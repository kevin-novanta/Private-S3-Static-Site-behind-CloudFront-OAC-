pipeline {
  agent any

  options {
    timestamps()
    skipDefaultCheckout(true)
  }

  environment {
    AWS_REGION = 'us-east-1'
  }

  stages {
    stage('Register Parameters') {
      steps {
        script {
          properties([
            parameters([
              choice(
                name: 'ENV',
                choices: ['staging','prod'].join('\n'),
                description: 'Which environment to deploy?'
              )
            ])
          ])
        }
      }
    }

    stage('Checkout') {
      steps {
        // Start with a clean workspace to avoid half-initialized .git dirs
        deleteDir()

        // Explicit checkout avoids implicit lightweight behavior quirks
        git url: 'https://github.com/kevin-novanta/Private-S3-Static-Site-behind-CloudFront-OAC-',
            branch: 'main'
            // If the repo is private, add: credentialsId: 'your-github-creds-id'

        sh label: 'Show branch & commit', script: '''#!/usr/bin/env bash
set -euo pipefail
BRANCH=$(git rev-parse --abbrev-ref HEAD || echo unknown)
COMMIT=$(git rev-parse --short HEAD || echo unknown)
echo "Branch: ${BRANCH} | Commit: ${COMMIT}"
'''
      }
    }

    stage('Tools (aws + terraform)') {
      steps {
        sh script: '''#!/usr/bin/env bash
set -euo pipefail
export PATH="$WORKSPACE/.local/bin:$PATH"

# Ensure local bin exists (non-root friendly install location)
mkdir -p "$WORKSPACE/.local/bin" "$WORKSPACE/.local/aws"

# Basic packages only if we have apt and permissions; otherwise skip
if command -v apt-get >/dev/null 2>&1 && [ "$(id -u)" -eq 0 ]; then
  apt-get update -y && apt-get install -y unzip curl jq
fi

# Fallback: download jq locally if missing
if ! command -v jq >/dev/null 2>&1; then
  ARCH=$(uname -m)
  case "$ARCH" in
    x86_64|amd64) JQ_URL="https://github.com/stedolan/jq/releases/download/jq-1.6/jq-linux64" ;;
    aarch64|arm64) JQ_URL="https://github.com/stedolan/jq/releases/download/jq-1.6/jq-linux64" ;;
    *) echo "Warning: unknown arch $ARCH for jq; skipping" ; JQ_URL="" ;;
  esac
  if [ -n "$JQ_URL" ]; then
    curl -fsSL "$JQ_URL" -o "$WORKSPACE/.local/bin/jq" && chmod +x "$WORKSPACE/.local/bin/jq"
  fi
fi

# AWS CLI v2 — install locally (no sudo required)
if ! command -v aws >/dev/null 2>&1; then
  ARCH=$(uname -m)
  if [ "$ARCH" = "x86_64" ] || [ "$ARCH" = "amd64" ]; then
    DL=https://awscli.amazonaws.com/awscli-exe-linux-x86_64.zip
  else
    DL=https://awscli.amazonaws.com/awscli-exe-linux-aarch64.zip
  fi
  curl -fsSL "$DL" -o awscliv2.zip
  rm -rf aws || true
  unzip -q awscliv2.zip
  ./aws/install -i "$WORKSPACE/.local/aws" -b "$WORKSPACE/.local/bin"
  aws --version
fi

# Terraform — install locally (no sudo required)
if ! command -v terraform >/dev/null 2>&1; then
  TF_VERSION=1.8.5
  ARCH=$(uname -m)
  case "$ARCH" in
    x86_64|amd64) TF_ZIP="terraform_${TF_VERSION}_linux_amd64.zip" ;;
    aarch64|arm64) TF_ZIP="terraform_${TF_VERSION}_linux_arm64.zip" ;;
    *) echo "Unsupported arch $ARCH"; exit 1 ;;
  esac
  curl -fsSL "https://releases.hashicorp.com/terraform/${TF_VERSION}/${TF_ZIP}" -o tf.zip
  unzip -o tf.zip -d "$WORKSPACE/.local/bin"
  terraform -version
fi
'''
      }
    }

    stage('Terraform outputs') {
      steps {
        script {
          env.ENV_DIR = "Infra/Terraform/environments/${params.ENV}"
        }
        sh script: '''#!/usr/bin/env bash
set -euo pipefail
export PATH="$WORKSPACE/.local/bin:$PATH"
cd "${ENV_DIR}"
          terraform init -input=false -upgrade
          echo "BUCKET=$(terraform output -raw s3_bucket_name)"                 >  "$WORKSPACE/env.out"
          echo "DISTID=$(terraform output -raw cloudfront_distribution_id)"    >> "$WORKSPACE/env.out"
          echo "CDN=$(terraform output -raw cdn_url)"                          >> "$WORKSPACE/env.out"
          echo "ENV_DIR=${ENV_DIR}"                                            >> "$WORKSPACE/env.out"
        '''
        script {
          def props = readProperties file: 'env.out'
          env.BUCKET  = props['BUCKET']
          env.DISTID  = props['DISTID']
          env.CDN     = props['CDN']
          env.ENV_DIR = props['ENV_DIR']
          echo "Resolved: bucket=${env.BUCKET}, dist=${env.DISTID}, cdn=${env.CDN}, envdir=${env.ENV_DIR}"
        }
      }
    }

    stage('Deploy (sync + invalidate + smoke)') {
      steps {
        script {
          // Choose credentials per environment. You already created staging IDs.
          // If you add prod later, create matching Jenkins credentials with these IDs.
          def keyIdId     = (params.ENV == 'prod') ? 'aws-prod-access-key-id'           : 'aws-staging-access-key-id'
          def secretKeyId = (params.ENV == 'prod') ? 'aws-prod-secret-access-key'       : 'aws-staging-secret-access-key'

          withCredentials([
            string(credentialsId: keyIdId,     variable: 'AWS_ACCESS_KEY_ID'),
            string(credentialsId: secretKeyId, variable: 'AWS_SECRET_ACCESS_KEY')
          ]) {
            sh script: '''#!/usr/bin/env bash
set -euo pipefail
export PATH="$WORKSPACE/.local/bin:$PATH"
              aws s3 sync site/ "s3://${BUCKET}" --delete

              aws cloudfront create-invalidation \
                --distribution-id "$DISTID" \
                --paths "/*"

              chmod +x Scripts/smoke.sh
              CDN_HOST="${CDN#https://}" SITE_BUCKET="$BUCKET" DIST_ID="$DISTID" ./Scripts/smoke.sh | tee smoke.log
            '''
          }
        }
      }
    }
  }

  post {
    always {
      archiveArtifacts artifacts: 'smoke.log', onlyIfSuccessful: false, allowEmptyArchive: true
    }
    success {
      echo "✅ ${params.ENV} deploy & smoke passed"
    }
    failure {
      echo "❌ ${params.ENV} deploy failed — see stage logs"
    }
  }
}