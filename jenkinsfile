pipeline {
  agent any

  options {
    timestamps()
    skipDefaultCheckout(true)
  }

  environment {
    AWS_REGION = 'us-east-1'
    AWS_DEFAULT_REGION = 'us-east-1'
    TF_CLI_ARGS = '-no-color'
  }

  stages {
    stage('Register Parameters') {
      steps {
        script {
          properties([
            parameters([
              choice(
                name: 'ENV',
                choices: ['staging','prod'].join('\n'),
                description: 'Which environment to deploy?'
              )
            ])
          ])
        }
      }
    }

    stage('Checkout') {
      steps {
        // Start with a clean workspace to avoid half-initialized .git dirs
        deleteDir()

        // Explicit checkout avoids implicit lightweight behavior quirks
        git url: 'https://github.com/kevin-novanta/Private-S3-Static-Site-behind-CloudFront-OAC-',
            branch: 'main'
            // If the repo is private, add: credentialsId: 'your-github-creds-id'

        sh label: 'Show branch & commit', script: '''#!/usr/bin/env bash
set -euo pipefail
BRANCH=$(git rev-parse --abbrev-ref HEAD || echo unknown)
COMMIT=$(git rev-parse --short HEAD || echo unknown)
echo "Branch: ${BRANCH} | Commit: ${COMMIT}"
'''
      }
    }

    stage('Tools (aws + terraform)') {
      steps {
        sh script: '''#!/usr/bin/env bash
set -euo pipefail
export PATH="$WORKSPACE/.local/bin:$PATH"

# Ensure local bin exists (non-root friendly install location)
mkdir -p "$WORKSPACE/.local/bin" "$WORKSPACE/.local/aws"

# Basic packages only if we have apt and permissions; otherwise skip
if command -v apt-get >/dev/null 2>&1 && [ "$(id -u)" -eq 0 ]; then
  apt-get update -y && apt-get install -y unzip curl jq
fi

# Fallback: download jq locally if missing
if ! command -v jq >/dev/null 2>&1; then
  ARCH=$(uname -m)
  case "$ARCH" in
    x86_64|amd64) JQ_URL="https://github.com/stedolan/jq/releases/download/jq-1.6/jq-linux64" ;;
    aarch64|arm64) JQ_URL="https://github.com/stedolan/jq/releases/download/jq-1.6/jq-linux64" ;;
    *) echo "Warning: unknown arch $ARCH for jq; skipping" ; JQ_URL="" ;;
  esac
  if [ -n "$JQ_URL" ]; then
    curl -fsSL "$JQ_URL" -o "$WORKSPACE/.local/bin/jq" && chmod +x "$WORKSPACE/.local/bin/jq"
  fi
fi

# AWS CLI v2 — install locally (no sudo required)
if ! command -v aws >/dev/null 2>&1; then
  ARCH=$(uname -m)
  if [ "$ARCH" = "x86_64" ] || [ "$ARCH" = "amd64" ]; then
    DL=https://awscli.amazonaws.com/awscli-exe-linux-x86_64.zip
  else
    DL=https://awscli.amazonaws.com/awscli-exe-linux-aarch64.zip
  fi
  curl -fsSL "$DL" -o awscliv2.zip
  rm -rf aws || true
  unzip -q awscliv2.zip
  ./aws/install -i "$WORKSPACE/.local/aws" -b "$WORKSPACE/.local/bin"
  aws --version
fi

# Terraform — install locally (no sudo required)
if ! command -v terraform >/dev/null 2>&1; then
  TF_VERSION=1.8.5
  ARCH=$(uname -m)
  case "$ARCH" in
    x86_64|amd64) TF_ZIP="terraform_${TF_VERSION}_linux_amd64.zip" ;;
    aarch64|arm64) TF_ZIP="terraform_${TF_VERSION}_linux_arm64.zip" ;;
    *) echo "Unsupported arch $ARCH"; exit 1 ;;
  esac
  curl -fsSL "https://releases.hashicorp.com/terraform/${TF_VERSION}/${TF_ZIP}" -o tf.zip
  unzip -o tf.zip -d "$WORKSPACE/.local/bin"
  terraform -version
fi
'''
      }
    }

    stage('Terraform outputs') {
  steps {
    script {
      env.ENV_DIR = "Infra/Terraform/environments/${params.ENV}"
    }
    sh script: '''#!/usr/bin/env bash
set -euo pipefail
export PATH="$WORKSPACE/.local/bin:$PATH"
export TF_CLI_ARGS="-no-color"

cd "${ENV_DIR}"
terraform init -input=false -upgrade 1>&2

# Export outputs to JSON, then to simple key=value properties
terraform output -json > tf-outputs.json

# Expecting keys: s3_bucket_name, cloudfront_distribution_id, and either cdn_hostname or cdn_url
jq -r '
  to_entries
  | map("\\(.key)=\\(.value.value)")
  | .[]
' tf-outputs.json > tf-out.properties

# Move properties file to workspace root for Jenkins steps
cp tf-out.properties "$WORKSPACE/tf-out.properties"
'''
    // Read properties into env vars
    script {
      def props = readProperties file: 'tf-out.properties'

      // prefer cdn_hostname; fall back to cdn_url
      def cdnHost = (props['cdn_hostname'] ?: '').trim()
      if (!cdnHost) {
        def cdnUrl = (props['cdn_url'] ?: '').trim()
        if (cdnUrl) {
          cdnHost = cdnUrl.replaceFirst('^https?://', '').replaceAll('/$', '')
        }
      }

      env.SITE_BUCKET = (props['s3_bucket_name'] ?: '').trim()
      env.DIST_ID     = (props['cloudfront_distribution_id'] ?: '').trim()
      env.CDN_HOST    = cdnHost

      echo "Resolved: bucket=${env.SITE_BUCKET}, dist=${env.DIST_ID}, cdn=${env.CDN_HOST}, envdir=${env.ENV_DIR}"
    }
  }
  post {
    always {
      archiveArtifacts artifacts: 'tf-outputs.json, tf-out.properties', onlyIfSuccessful: false, allowEmptyArchive: true
    }
  }
}

    stage('Deploy (sync + invalidate + smoke)') {
      steps {
        script {
          // Sanity checks
          if (!(env.SITE_BUCKET ==~ "^[a-z0-9.\\-_]{3,255}$")) {
            error "S3 bucket name looks invalid: '${env.SITE_BUCKET}'"
          }
          if (!(env.DIST_ID ==~ "^[A-Z0-9]{13,}$")) {
            error "Distribution ID looks invalid: '${env.DIST_ID}'"
          }
          if (!env.CDN_HOST || !(env.CDN_HOST ==~ "^[A-Za-z0-9.-]+\$")) {
            error "CDN host looks invalid: '${env.CDN_HOST}'"
          }

          // Choose credentials per environment. You already created staging IDs.
          def keyIdId     = (params.ENV == 'prod') ? 'aws-prod-access-key-id'           : 'aws-staging-access-key-id'
          def secretKeyId = (params.ENV == 'prod') ? 'aws-prod-secret-access-key'       : 'aws-staging-secret-access-key'

          withCredentials([
            string(credentialsId: keyIdId,     variable: 'AWS_ACCESS_KEY_ID'),
            string(credentialsId: secretKeyId, variable: 'AWS_SECRET_ACCESS_KEY')
          ]) {
            sh script: '''#!/usr/bin/env bash
set -euo pipefail
export PATH="$WORKSPACE/.local/bin:$PATH"
export AWS_DEFAULT_REGION="${AWS_DEFAULT_REGION:-us-east-1}"

aws s3 sync site/ "s3://${SITE_BUCKET}" --delete

aws cloudfront create-invalidation \
  --distribution-id "$DIST_ID" \
  --paths "/*"

chmod +x Scripts/smoke.sh
CDN_HOST="${CDN_HOST}" SITE_BUCKET="$SITE_BUCKET" DIST_ID="$DIST_ID" ./Scripts/smoke.sh | tee smoke.log
'''
          }
        }
      }
    }
  }

  post {
    always {
      archiveArtifacts artifacts: 'smoke.log', onlyIfSuccessful: false, allowEmptyArchive: true
    }
    success {
      echo "✅ ${params.ENV} deploy & smoke passed"
    }
    failure {
      echo "❌ ${params.ENV} deploy failed — see stage logs"
    }
  }
}